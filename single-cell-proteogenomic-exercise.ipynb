{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single cell proteogenomics\n",
    "---\n",
    "## Input data\n",
    "\n",
    "This workbook is based on the work posted in this repository: https://github.com/CellProfiling/SingleCellProteogenomics.\n",
    "\n",
    "Please download the input folder, which is located here (~650 MB): https://drive.google.com/file/d/149ICTtieYjuKWZoLwRLzimwff0n6eWqw/view?usp=sharing.\n",
    "\n",
    "Place this folder in the same directory as this file.\n",
    "\n",
    "## Imaging proteomics\n",
    "\n",
    "The first dataset that you will use is an imaging proteomic dataset. This dataframe contains the postprocessing results (using CellProfiler) for thousands of images containing four channels (colors) that contain information about a protein of interest, a marker channel (microtubules), and two fluorescence markers that precisely characterize the cell cycle time for each individual cell.\n",
    "\n",
    "The dataframe contains information for each individual cell in this dataset (~200,000 cells). One particular challenge of this dataset is that each image (and thus each cell in each image) contains information for only one protein. This is in stark comparison to techniques like single-cell RNA sequencing, which contains measurements for a full complement genes (~13,000) in each cell. Therefore, this single-cell proteomic data can be considered _very sparse_ data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.mixture\n",
    "import decimal\n",
    "import scipy.optimize\n",
    "from copy import deepcopy\n",
    "import copy\n",
    "plt.rcParams['pdf.fonttype'], plt.rcParams['ps.fonttype'], plt.rcParams['savefig.dpi'] = 42, 42, 300 #Make PDF text readable\n",
    "\n",
    "# EMPTYWELLS: These wells on the last plate didn't have cells; the segmentation algorithm still annotated some, so remove them\n",
    "EMPTYWELLS = set([\"B11_6745\",\"C11_6745\",\"D11_6745\",\"E11_6745\",\"F11_6745\",\"G11_6745\",\"H11_6745\",\n",
    "    \"A12_6745\",\"B12_6745\",\"C12_6745\",\"D12_6745\",\"E12_6745\",\"F12_6745\",\"G12_6745\"]) \n",
    "\n",
    "# MIN_CELL_COUNT: Minimum number of cells per sample required for cell cycle analysis with pseudotime\n",
    "MIN_CELL_COUNT = 60 \n",
    "\n",
    "# Let's make some output folders\n",
    "if not os.path.exists(\"output/\"): os.mkdir(\"output/\")\n",
    "if not os.path.exists(\"output/pickles/\"): os.mkdir(\"output/pickles/\")\n",
    "if not os.path.exists(\"figures/\"): os.mkdir(\"figures/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the raw imaging proteomic dataframe\n",
    "print(\"reading raw protein IF data\")\n",
    "my_df1 = pd.read_csv(\"input/ProteinData/FucciDataFirstPlates.csv.gz\")\n",
    "my_df2 = pd.read_csv(\"input/ProteinData/FucciDataSecondPlates.csv.gz\")\n",
    "my_df = pd.concat((my_df1, my_df2), sort=True)\n",
    "print(\"loaded raw data\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output column information\n",
    "print(\",\".join(my_df.columns))\n",
    "print(my_df.shape)\n",
    "my_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of dataframe\n",
    "\n",
    "### Size of the dataframe\n",
    "**This dataframe has information for each of hundreds of cells for ~1200 proteins.**\n",
    "Note there are 637,104 segmented objects above. That's a lot of cells! Pretty cool stuff.\n",
    "\n",
    "### Dataframe columns\n",
    "#### Unique identifiers\n",
    "* ImageNumber:\n",
    "    * Unique identifier for image\n",
    "* ObjectNumber:\n",
    "    * Unique identifier for the object within the image\n",
    "* plate:\n",
    "    * Images were collected for cells seeded in 96-well plates; this is the plate identifier, which was important for batch correction\n",
    "* well:\n",
    "    * This is the well within the plate\n",
    "* well_plate:\n",
    "    * Concatenated identifiers\n",
    "* well_plate_imagenb:\n",
    "    * Concatenated identifiers\n",
    "\n",
    "#### Cell shape and segmentation\n",
    "* AreaShape_Area,AreaShape_Perimeter,Area_cell,Area_cyto,perimeter_cell,perimeter_cyto:\n",
    "    * area of the cell, circumference of the cell, area of the cytoplasm (minus nuclear segmented area)\n",
    "* Z1prob,Z2prob,Z3prob,z.1,z.2,z.3,a,classification,d,d1\n",
    "    * These pertain to the segmentation of cells\n",
    "    \n",
    "#### Intensities\n",
    "* Integrated_ab_cell,Integrated_ab_cyto,Integrated_green_cell,Integrated_green_cyto,Integrated_mt_cell,Integrated_mt_cyto,Integrated_red_cell,Integrated_red_cyto:\n",
    "    * Integrated intensities of **protein of interest (ab)**\n",
    "    * Integrated intensity of **geminin-GFP construct (green)**\n",
    "    * Integrated intensity of **CDT1-RFT construct (red)**\n",
    "    * Integrated intensity of the interal control of **microtubules (mt)**\n",
    "    * These intensities are split between the **cell** and **cytoplasm**\n",
    "* Mean_Green_Fucci_Cyto,Mean_Green_Fucci_cell,Mean_Red_Fucci_Cyto,Mean_Red_Fucci_cell,Mean_ab_Cyto,Mean_ab_cell,Mean_mt_Cyto,Mean_mt_cell:\n",
    "    * Similar to above but mean intensity\n",
    "* Median_Green_Fucci_Cyto,Median_Green_Fucci_cell,Median_Red_Fucci_Cyto,Median_Red_Fucci_cell,Median_ab_Cyto,Median_ab_cell,Median_mt_Cyto,Median_mt_cell:\n",
    "    * Similar to above but median intensity\n",
    "* Intensity_IntegratedIntensity_CorrResizedGreenFUCCI,Intensity_IntegratedIntensity_CorrResizedRedFUCCI,Intensity_IntegratedIntensity_ResizedAb,Intensity_IntegratedIntensity_Resizedmt:\n",
    "    * Similar to above, but for resized areas within CellProfiler\n",
    "* Intensity_MeanIntensity_CorrResizedGreenFUCCI,Intensity_MeanIntensity_CorrResizedRedFUCCI,Intensity_MeanIntensity_ResizedAb,Intensity_MeanIntensity_Resizedmt:\n",
    "    * Similar to above, but mean intensity of the pixels within each area\n",
    "* Intensity_MedianIntensity_CorrResizedGreenFUCCI,Intensity_MedianIntensity_CorrResizedRedFUCCI,Intensity_MedianIntensity_ResizedAb,Intensity_MedianIntensity_Resizedmt:\n",
    "    * Similar to above but median intensity of the pixels within each area\n",
    "* log_green,log_red:\n",
    "    * log intensities of the FUCCI markers; I ended up recalculating these, I believe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering\n",
    "There are some important things we need to filter for before proceeding to make sure we're looking at cells and not artifacts:\n",
    "(3-5 mins)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Such a large dataframe that I chose to separate out the columns into separate variables when I started this project\n",
    "# Probably a better way to do that! But it got the job done.\n",
    "def read_sample_info(df):\n",
    "    '''Get the metadata for all the samples'''\n",
    "    plate = np.asarray(df.plate)\n",
    "    u_plate = np.unique(plate)\n",
    "    well_plate = np.asarray(df.well_plate)\n",
    "    imgnb = np.asarray(df.ImageNumber)\n",
    "    well_plate_imgnb = np.asarray([f\"{wp}_{imgnb[i]}\" for i,wp in enumerate(well_plate)])\n",
    "    u_well_plates = np.unique(well_plate)\n",
    "    ab_objnum = np.asarray(df.ObjectNumber)\n",
    "    well_plate_imgnb_objnb = np.asarray([f\"{wp}_{imgnb[i]}_{ab_objnum[i]}\" for i,wp in enumerate(well_plate)])\n",
    "    area_cell = np.asarray(df.Area_cell)\n",
    "    area_nuc = np.asarray(df.AreaShape_Area)\n",
    "    area_cyto = np.asarray(df.Area_cyto)\n",
    "    name_df = pd.read_csv(\"input/ProteinData/FucciStainingSummaryFirstPlates.csv\")\n",
    "    wppp1, ensggg1, abbb1, rrrr, cccc1 = list(name_df[\"well_plate\"]), list(name_df[\"ENSG\"]), list(name_df[\"Antibody\"]), list(name_df[\"Results_final_update\"]), list(name_df[\"Compartment\"])\n",
    "    name_df2 = pd.read_csv(\"input/ProteinData/FucciStainingSummarySecondPlates.csv\")\n",
    "    wppp2, ensggg2, abbb2, cccc2 = list(name_df2[\"well_plate\"]), list(name_df2[\"ENSG\"]), list(name_df2[\"Antibody\"]), list(name_df2[\"Compartment\"])\n",
    "    wppp, ensggg, abbb, cccc = wppp1 + wppp2, ensggg1 + ensggg2, abbb1 +  abbb2, cccc1 + cccc2\n",
    "    ensg_dict = dict([(wppp[i], ensggg[i]) for i in range(len(wppp))])\n",
    "    ab_dict = dict([(wppp[i], abbb[i]) for i in range(len(wppp))])\n",
    "    result_dict = dict([(wppp[i], rrrr[i]) for i in range(len(wppp1))])\n",
    "    compartment_dict = dict([(wppp[i], cccc[i]) for i in range(len(wppp))])\n",
    "    ENSG = np.asarray([ensg_dict[wp] if wp in ensg_dict else \"\" for wp in well_plate])\n",
    "    antibody = np.asarray([ab_dict[wp] if wp in ab_dict else \"\" for wp in well_plate])\n",
    "    result = np.asarray([result_dict[wp] if wp in result_dict else \"\" for wp in well_plate])\n",
    "    compartment = np.asarray([compartment_dict[wp] if wp in compartment_dict else \"\" for wp in well_plate])\n",
    "    return plate, u_plate, well_plate, well_plate_imgnb, well_plate_imgnb_objnb, u_well_plates, ab_objnum, area_cell, area_nuc, area_cyto, ensg_dict, ab_dict, result_dict, compartment_dict, ENSG, antibody, result, compartment\n",
    "\n",
    "def read_sample_data(df):\n",
    "    '''Read antibody intensity data for each sample and save it to a file for later use.'''\n",
    "    # Antibody data (mean intensity)\n",
    "    ab_nuc = df.Intensity_MeanIntensity_ResizedAb\n",
    "    ab_cyto = df.Mean_ab_Cyto\n",
    "    ab_cell = df.Mean_ab_cell\n",
    "    mt_cell = df.Mean_mt_cell\n",
    "\n",
    "    # Fucci data (mean intensity)\n",
    "    green_fucci = np.asarray(df.Intensity_MeanIntensity_CorrResizedGreenFUCCI)\n",
    "    red_fucci = np.asarray(df.Intensity_MeanIntensity_CorrResizedRedFUCCI)\n",
    "\n",
    "    return ab_nuc, ab_cyto, ab_cell, mt_cell, green_fucci, red_fucci\n",
    "\n",
    "def previous_results(u_well_plates, result_dict, ensg_dict, ab_dict):\n",
    "    '''Process the results metadata into lists of previously annotated CCD proteins'''\n",
    "    wp_ensg = np.asarray([ensg_dict[wp] if wp in ensg_dict else \"\" for wp in u_well_plates])\n",
    "    wp_ab = np.asarray([ab_dict[wp] if wp in ab_dict else \"\" for wp in u_well_plates])\n",
    "    wp_prev_ccd = np.asarray([wp in result_dict and result_dict[wp].startswith(\"ccd\") for wp in u_well_plates])\n",
    "    wp_prev_notccd = np.asarray([wp in result_dict and result_dict[wp].startswith(\"notccd\") for wp in u_well_plates])\n",
    "    wp_prev_negative = np.asarray([wp in result_dict and result_dict[wp].startswith(\"negative\") for wp in u_well_plates])\n",
    "    prev_ccd_ensg = wp_ensg[wp_prev_ccd]\n",
    "    prev_notccd_ensg = wp_ensg[wp_prev_notccd]\n",
    "    prev_negative_ensg = wp_ensg[wp_prev_negative]\n",
    "    \n",
    "    return wp_ensg, wp_ab, wp_prev_ccd, wp_prev_notccd, wp_prev_negative, prev_ccd_ensg, prev_notccd_ensg, prev_negative_ensg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plate, u_plate, well_plate, well_plate_imgnb, well_plate_imgnb_objnb, u_well_plates, ab_objnum, area_cell, area_nuc, area_cyto, ensg_dict, ab_dict, result_dict, compartment_dict, ENSG, antibody, result, compartment = read_sample_info(my_df)\n",
    "\n",
    "print(f\"{len(my_df)}: number of cells before filtering empty wells\")\n",
    "my_df = my_df[~my_df.well_plate.isin(EMPTYWELLS)]\n",
    "print(f\"{len(my_df)}: number of cells after filtering empty wells\")\n",
    "\n",
    "my_df_filtered = my_df\n",
    "print(\"filtering out of focus\")\n",
    "oof = pd.read_csv(\"input/ProteinData/OutOfFocusImages.txt\", header=None)[0]\n",
    "well_plate = np.asarray(my_df_filtered.well_plate)\n",
    "imgnb = np.asarray(my_df_filtered.ImageNumber)\n",
    "well_plate_imgnb = np.asarray([f\"{wp}_{imgnb[i]}\" for i,wp in enumerate(well_plate)])\n",
    "print(f\"{len(my_df_filtered)}: number of cells before filtering out of focus images\")\n",
    "my_df_filtered = my_df_filtered[~np.isin(well_plate_imgnb, oof)]\n",
    "print(f\"{len(my_df_filtered)}: number of cells after filtering out of focus images\")\n",
    "print(\"finished filtering\")\n",
    "\n",
    "print(\"filtering negative staining\")\n",
    "new_data_or_nonnegative_stain = [wp not in result_dict or (not result_dict[wp].lower().startswith(\"negative\") and not wp.startswith(\"H12\")) for wp in my_df_filtered.well_plate]\n",
    "print(f\"{len(my_df_filtered)}: number of cells before filtering negative staining from first batch\")\n",
    "my_df_filtered = my_df_filtered[new_data_or_nonnegative_stain]\n",
    "print(f\"{len(my_df_filtered)}: number of cells after filtering negative staining from first batch\")\n",
    "print(\"finished filtering\")\n",
    "    \n",
    "print(\"filtering bad fields of view (negative staining, unspecific, etc)\")\n",
    "filterthese = pd.read_csv(\"input/ProteinData/FOV_ImgNum_Lookup.csv\")\n",
    "badfov = filterthese[\"well_plate_imgnb\"][(filterthese[\"UseImage\"] == 0)]\n",
    "well_plate = np.asarray(my_df_filtered.well_plate)\n",
    "imgnb = np.asarray(my_df_filtered.ImageNumber)\n",
    "well_plate_imgnb = np.asarray([f\"{wp}_{imgnb[i]}\" for i,wp in enumerate(well_plate)])\n",
    "negative_controls = np.asarray([wp.startswith(\"H12\") for wp in well_plate])\n",
    "print(f\"{len(my_df_filtered)}: number of cells before filtering out of focus images\")\n",
    "my_df_filtered = my_df_filtered[~np.isin(well_plate_imgnb, badfov) & ~negative_controls]\n",
    "print(f\"{len(my_df_filtered)}: number of cells after filtering out of focus images\")\n",
    "print(\"finished filtering\")\n",
    "\n",
    "print(\"filtering failed antibodies\")\n",
    "failedab = np.genfromtxt(\"input/ProteinData/RecentlyFailedAntibodies.txt\", dtype='str')\n",
    "print(f\"{len(my_df_filtered)}: number of cells before filtering antibodies failed in HPAv19\")\n",
    "my_df_filtered = my_df_filtered[~np.isin([ab_dict[wp] for wp in my_df_filtered.well_plate], failedab)]\n",
    "print(f\"{len(my_df_filtered)}: number of cells after filtering antibodies failed in HPAv19\")\n",
    "print(\"finished filtering\")\n",
    "\n",
    "print(\"filtering mitotic proteins\")\n",
    "mitoticab = np.genfromtxt(\"input/ProteinData/RemoveMitoticAndMicrotubules.txt\", dtype='str')\n",
    "print(f\"{len(my_df_filtered)}: number of cells before filtering mitotic/microtubule proteins\")\n",
    "my_df_filtered = my_df_filtered[~np.isin([ab_dict[wp] for wp in my_df_filtered.well_plate], mitoticab)]\n",
    "print(f\"{len(my_df_filtered)}: number of cells after filtering mitotic/microtubule proteins\")\n",
    "print(\"finished filtering\")\n",
    "\n",
    "my_df_manually_filtered = my_df_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1:\n",
    "Implement a filter for the nucleus area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_areas(areas, title):\n",
    "    '''Histogram for areas of cell/nuc/cytoplasm'''\n",
    "    bins = plt.hist(areas, bins=100, alpha=0.5)\n",
    "    plt.vlines(np.mean(areas), 0, np.max(bins[0]))\n",
    "    plt.vlines(np.mean(areas) - 2 * np.std(areas), 0, np.max(bins[0]))\n",
    "    plt.vlines(np.mean(areas) + 2 * np.std(areas), 0, np.max(bins[0]))\n",
    "    plt.title(title)\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.xlabel(\"Area\")\n",
    "    plt.savefig(f\"figures/areas{title}.png\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "print(\"There are some suspiciously large nuclei!\")\n",
    "print(\"Note that there is already a cutoff on the smaller side, but we probably need to be careful about not considering those enormous ones.\")\n",
    "\n",
    "plot_areas(my_df.AreaShape_Area, \"area_nuc\")\n",
    "my_df_filtered = my_df_manually_filtered\n",
    "print(\"filtering super big nuclei\")\n",
    "\n",
    "### EXERCISE 1: Implement a cutoff for removing super large nuclei, which are likely artifacts\n",
    "\n",
    "print(\"finished filtering on nuclei\")\n",
    "plot_areas(my_df_filtered.AreaShape_Area, \"area_nuc_filtered\")\n",
    "my_df_filtered_areas = my_df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Filter low cell counts per sample'''\n",
    "my_df_filtered_cellcount = my_df_filtered_areas\n",
    "well_plate = np.asarray(my_df_filtered_cellcount.well_plate)\n",
    "u_well_plates = np.unique(my_df_filtered_cellcount.well_plate)\n",
    "cell_count_dict = {}\n",
    "for wp in well_plate:\n",
    "    if wp in cell_count_dict: cell_count_dict[wp] += 1\n",
    "    else: cell_count_dict[wp] = 1\n",
    "cell_counts = np.array([cell_count_dict[wp] for wp in well_plate])\n",
    "print(\"filtering low cell counts\")\n",
    "my_df_filtered_cellcount = my_df_filtered_cellcount[cell_counts >= MIN_CELL_COUNT]\n",
    "print(f\"{len(my_df_filtered_areas)}: number of cells before filtering out samples with < {MIN_CELL_COUNT} cells\")\n",
    "print(f\"{len(my_df_filtered_cellcount)}: number of cells after filtering out samples with < {MIN_CELL_COUNT} cells\")\n",
    "print(\"finished filtering on cell count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filtering for proteins that are annotated as variable\n",
    "plate, u_plate, well_plate, well_plate_imgnb, well_plate_imgnb_objnb, u_well_plates, ab_objnum, area_cell, area_nuc, area_cyto, ensg_dict, ab_dict, result_dict, compartment_dict, ENSG, antibody, result, compartment = read_sample_info(my_df_filtered_cellcount)\n",
    "\n",
    "my_df_filtered_variation, my_df_filtered_novariation = my_df_filtered_cellcount, my_df_filtered_cellcount\n",
    "variable_firstbatch = np.asarray([wp in result_dict and not result_dict[wp].replace(\" \",\"\").startswith(\"novariation\") for wp in my_df_filtered_cellcount.well_plate])\n",
    "\n",
    "varann_secondbatch = pd.read_csv(\"input/ProteinData/SecondBatchVariableLookup.csv\")\n",
    "variable_ann_secondbatch = np.asarray([str(vv).lower().startswith(\"yes\") for vv in varann_secondbatch[\"IsVariable\"]])\n",
    "variable_wp_secondbatch = np.asarray(varann_secondbatch[\"well_plate\"][variable_ann_secondbatch])\n",
    "variable_secondbatch = np.isin(my_df_filtered_cellcount.well_plate, variable_wp_secondbatch)\n",
    "\n",
    "my_df_filtered_variation = my_df_filtered_cellcount[variable_firstbatch | variable_secondbatch]\n",
    "my_df_filtered_novariation = my_df_filtered_cellcount[~(variable_firstbatch | variable_secondbatch)]\n",
    "print(f\"{len(my_df_filtered_cellcount)}: number of cells before filtering for variation\")\n",
    "print(f\"{len(my_df_filtered_variation)}: number of cells in samples with variation\")\n",
    "print(f\"{len(my_df_filtered_novariation)}: number of cells in samples without variation\")\n",
    "\n",
    "## Making sure there is compartment information, which were largely ones that were found in mitotic structures (biologically defined as cell cycle dependent, CCD)\n",
    "wp_iscell = np.asarray([compartment_dict[wp].lower().startswith(\"cell\") if wp in compartment_dict else False for wp in u_well_plates])\n",
    "wp_isnuc = np.asarray([compartment_dict[wp].lower().startswith(\"nuc\") if wp in compartment_dict else False for wp in u_well_plates])\n",
    "wp_iscyto = np.asarray([compartment_dict[wp].lower().startswith(\"cyto\") if wp in compartment_dict else False for wp in u_well_plates])\n",
    "\n",
    "wp_nocompartmentinfo = ~wp_iscell & ~wp_isnuc & ~wp_iscyto\n",
    "print(f\"{sum(wp_nocompartmentinfo)}: samples without compartment information; to be filtered since they're biologically defined as CCD and not included in the analysis\")\n",
    "print(f\"{len(my_df_filtered_variation)}: number of cells before filtering for compartment information\")\n",
    "my_df_filtered_compartmentvariation = my_df_filtered_variation[~np.isin(my_df_filtered_variation.well_plate, u_well_plates[wp_nocompartmentinfo])]\n",
    "print(f\"{len(my_df_filtered_compartmentvariation)}: number of cells after filtering for compartment information\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we're done with filtering the dataframe\n",
    "\n",
    "* We dropped from over 600,000 segmented objects to 264,260 that we are confident are cells\n",
    "* Let's look into what we can learn from the intensities of the markers and protein staining in those cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we need to correct for batch effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take \n",
    "plate, u_plate, well_plate, well_plate_imgnb, well_plate_imgnb_objnb, u_well_plates, ab_objnum, area_cell, area_nuc, area_cyto, ensg_dict, ab_dict, result_dict, compartment_dict, ENSG, antibody, result, compartment = read_sample_info(\n",
    "    my_df_filtered_compartmentvariation\n",
    ")\n",
    "ab_nuc, ab_cyto, ab_cell, mt_cell, green_fucci, red_fucci = read_sample_data(\n",
    "    my_df_filtered_compartmentvariation\n",
    ")\n",
    "wp_ensg, wp_ab, wp_prev_ccd, wp_prev_notccd, wp_prev_negative, prev_ccd_ensg, prev_notccd_ensg, prev_negative_ensg = previous_results(\n",
    "    u_well_plates, result_dict, ensg_dict, ab_dict\n",
    ")\n",
    "\n",
    "plt.hist2d(np.log10(green_fucci), np.log10(red_fucci), bins=200)\n",
    "plt.xlabel(\"Log10 Green Fucci Intensity\")\n",
    "plt.ylabel(\"Log10 Red Fucci Intensity\")\n",
    "plt.savefig(\"figures/FucciPlotProteinIFData_unfiltered.png\")\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thinking about batch corrections\n",
    "\n",
    "This looks okay, right? Think again.\n",
    "\n",
    "**Exercise 2: Plot the fucci intensities for each plate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXERCISE 2: Display the fucci intensities for each plate. Do they need batch correction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thinking about batch corrections\n",
    "\n",
    "It's particularly noticable if you look at the minimum edge. The minimum of the green fucci log intensities are quite different per plate.\n",
    "\n",
    "The centers are also very different, which will make an impact later in the calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_center_fucci(green_fucci, red_fucci, u_plate, well_plate, plate):\n",
    "    '''Zero center and rescale FUCCI data in the log space'''\n",
    "    log_green_fucci, log_red_fucci = np.log10(green_fucci), np.log10(red_fucci)\n",
    "    wp_p_dict = dict([(str(p), plate == p) for p in u_plate])\n",
    "    logmed_green_fucci_p = dict([(str(p), np.log10(np.median(green_fucci[wp_p_dict[str(p)]]))) for p in u_plate])\n",
    "    logmed_red_fucci_p = dict([(str(p), np.log10(np.median(red_fucci[wp_p_dict[str(p)]]))) for p in u_plate])\n",
    "    logmed_green_fucci = np.array([logmed_green_fucci_p[wp.split(\"_\")[1]] for wp in well_plate])\n",
    "    logmed_red_fucci = np.array([logmed_red_fucci_p[wp.split(\"_\")[1]] for wp in well_plate])\n",
    "    log_green_fucci_zeroc = np.array(log_green_fucci) - logmed_green_fucci\n",
    "    log_red_fucci_zeroc = np.array(log_red_fucci) - logmed_red_fucci\n",
    "    log_green_fucci_zeroc_rescale = (log_green_fucci_zeroc - np.min(log_green_fucci_zeroc)) / np.max(log_green_fucci_zeroc)\n",
    "    log_red_fucci_zeroc_rescale = (log_red_fucci_zeroc - np.min(log_red_fucci_zeroc)) / np.max(log_red_fucci_zeroc)\n",
    "    fucci_data = np.column_stack([log_green_fucci_zeroc_rescale,log_red_fucci_zeroc_rescale])\n",
    "    result = (log_green_fucci, log_red_fucci,\n",
    "              log_green_fucci_zeroc, log_red_fucci_zeroc,\n",
    "              log_green_fucci_zeroc_rescale, log_red_fucci_zeroc_rescale,\n",
    "              fucci_data)\n",
    "    return result\n",
    "log_green_fucci, log_red_fucci, log_green_fucci_zeroc, log_red_fucci_zeroc, log_green_fucci_zeroc_rescale, log_red_fucci_zeroc_rescale, fucci_data = zero_center_fucci(\n",
    "    green_fucci, red_fucci, u_plate, well_plate, plate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXERCISE 2B: Display the fucci intensities overlayed and by plate again. \n",
    "# \n",
    "# Do you see any differences?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian clustering of the data\n",
    "\n",
    "Let's use some Gaussian clustering to see the three phases we expect from the data.\n",
    "\n",
    "This analysis was used as a mock-up bulk analysis for each of the phases to compare the number of genes called cell cycle dependent to how many would be called from bulk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Perform gaussian clustering of FUCCI data into 3 phases: G1, S, G2'''\n",
    "g1_idx, sph_idx, g2_idx = 2, 0, 1\n",
    "clusternames = [\n",
    "    \"G2\" if g2_idx == 0 else \"G1\" if g1_idx == 0 else \"S-ph\",\n",
    "    \"G2\" if g2_idx == 1 else \"G1\" if g1_idx == 1 else \"S-ph\",\n",
    "    \"G2\" if g2_idx == 2 else \"G1\" if g1_idx == 2 else \"S-ph\",\n",
    "]\n",
    "\n",
    "gaussian = sklearn.mixture.GaussianMixture(n_components=3, random_state=1, max_iter=500)\n",
    "cluster_labels = gaussian.fit_predict(np.array([log_green_fucci_zeroc_rescale, log_red_fucci_zeroc_rescale]).T)\n",
    "for cluster in range(3):\n",
    "    plt.hist2d(log_green_fucci_zeroc_rescale[cluster_labels == cluster],log_red_fucci_zeroc_rescale[cluster_labels == cluster],bins=200)\n",
    "    plt.title(f\"Gaussian clustered data, {clusternames[cluster]}\")\n",
    "    plt.xlabel(\"Log10 Green Fucci Intensity\")\n",
    "    plt.ylabel(\"Log10 Red Fucci Intensity\")\n",
    "    plt.savefig(f\"figures/FucciPlotProteinIFData_unfiltered_Gauss{cluster}.png\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def get_phase_strings(is_g1, is_sph, is_g2):\n",
    "    '''Make strings to represent the metacompartment'''\n",
    "    phasestring = np.array([\"G1\"] * len(is_g1))\n",
    "    phasestring[is_sph] = \"S\" \n",
    "    phasestring[is_g2] = \"G2\"\n",
    "    return phasestring\n",
    "\n",
    "g1 = cluster_labels == g1_idx\n",
    "sph = cluster_labels == sph_idx\n",
    "g2 = cluster_labels == g2_idx\n",
    "alpha_gauss, doGenerateBoxplotsPerGene = 0.05, False\n",
    "wp_cell_kruskal, wp_nuc_kruskal, wp_cyto_kruskal, wp_mt_kruskal = [],[],[],[]\n",
    "curr_wp_phases = []\n",
    "mockbulk_phases = np.array([\"  \"] * len(ab_cell))\n",
    "for iii, wp in enumerate(u_well_plates):\n",
    "    curr_well_inds = well_plate==wp\n",
    "    curr_wp_g1 = curr_well_inds & g1\n",
    "    curr_wp_sph = curr_well_inds & sph\n",
    "    curr_wp_g2 = curr_well_inds & g2\n",
    "    curr_wp_phase_list = get_phase_strings(g1[curr_well_inds], sph[curr_well_inds], g2[curr_well_inds])\n",
    "    mockbulk_phases[curr_well_inds] = np.asarray(curr_wp_phase_list)\n",
    "    curr_wp_phases.append(curr_wp_phase_list)\n",
    "    max_val_for_norm = np.max(ab_cell[curr_well_inds] if wp_iscell[iii] else ab_nuc[curr_well_inds] if wp_isnuc[iii] else ab_cyto[curr_well_inds])\n",
    "    max_mt_for_norm = np.max(mt_cell[curr_well_inds])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating a pseudotime based on markers for the cell cycle\n",
    "\n",
    "Looking at the fucci intensities, you'll notice they form a horseshoe going clockwise. One idea is to use a polar coordinate model to map these intensities on a circle, which was part of why it was important to center them in log-log space.\n",
    "\n",
    "Let's take a look at this polar coordinate model used to map cell cycle time onto these intensities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First, some setup:\n",
    "\n",
    "class FucciCellCycle:\n",
    "    '''\n",
    "    Object representing the length of the FUCCI cell cycle phase transitions, which\n",
    "    were manually determined by Diana M.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        # Length of the cell cycle observed for the FUCCI cell line\n",
    "        self.G1_LEN = 10.833 #hours (plus 10.833, so 13.458hrs for the S/G2 cutoff)\n",
    "        self.G1_S_TRANS = 2.625 #hours (plus 10.833 and 2.625 so 25.433 hrs for the G2/M cutoff)\n",
    "        self.S_G2_LEN = 11.975 #hours (this should be from the G2/M cutoff above to the end)\n",
    "        self.M_LEN = 0.5 # We excluded M-phase from this analysis\n",
    "\n",
    "        self.TOT_LEN = self.G1_LEN+self.G1_S_TRANS+self.S_G2_LEN\n",
    "\n",
    "        self.G1_PROP = self.G1_LEN / self.TOT_LEN\n",
    "        self.G1_S_PROP = self.G1_S_TRANS / self.TOT_LEN + self.G1_PROP\n",
    "        self.S_G2_PROP = self.S_G2_LEN / self.TOT_LEN + self.G1_S_PROP\n",
    "\n",
    "NBINS_POLAR_COORD = 150 # Number of bins for polar coord calculation, arbitrary choice for now\n",
    "WINDOW_FUCCI_PSEUDOTIME = 100 # Window used for visualizing FUCCI intensities over pseudotime\n",
    "fucci = FucciCellCycle() # Object representing FUCCI cell cycle phase durations\n",
    "\n",
    "## POLAR COORDINATE FUNCTIONS\n",
    "def calc_R(xc, yc, x, y):\n",
    "    '''Calculate the distance of each 2D points from the center (xc, yc)'''\n",
    "    return np.sqrt((x-xc)**2 + (y-yc)**2)\n",
    "def f_2(c,x,y):\n",
    "    '''Calculate the algebraic distance between the data points and the mean circle centered at c=(xc, yc)'''\n",
    "    print(c)\n",
    "    Ri = calc_R(c[0],c[1],x,y)\n",
    "    return Ri - Ri.mean()\n",
    "def cart2pol(x, y):\n",
    "    '''Convert cartesian coordinates to polar coordinates'''\n",
    "    rho = np.sqrt(x**2 + y**2)\n",
    "    phi = np.arctan2(y, x)\n",
    "    return(rho, phi)\n",
    "def pol_sort(inds, more_than_start, less_than_start, *args):\n",
    "    '''Sort data by polar coordinates and reorder based on the start position of the polar coordinate model'''\n",
    "    return [np.concatenate((arr[inds][more_than_start], arr[inds][less_than_start])) for arr in args]\n",
    "def pol2cart(rho, phi):\n",
    "    '''Apply uniform radius (rho) and convert back'''\n",
    "    x = rho * np.cos(phi)\n",
    "    y = rho * np.sin(phi)\n",
    "    return(x, y)\n",
    "\n",
    "\n",
    "## PLOTTING HELPERS\n",
    "def plot_annotate_time(R_2, start_phi, fraction):\n",
    "    '''Pseudotime annotation helper for point on plot'''\n",
    "    pt = pol2cart(R_2,start_phi + (1 - fraction) * 2 * np.pi)\n",
    "    plt.scatter(pt[0],pt[1],c='c',linewidths=4)\n",
    "    plt.annotate(f\"  {round(fraction * fucci.TOT_LEN, 2)} hrs\", (pt[0], pt[1]))\n",
    "    \n",
    "def drange(x, y, jump):\n",
    "    '''Increment `x` by a decimal `jump` until greater than `y`'''\n",
    "    while x < y:\n",
    "        yield float(x)\n",
    "        x += decimal.Decimal(jump)\n",
    "\n",
    "def fucci_hist2d(centered_data, cart_data_ur, start_pt, g1_end_pt, g1s_end_pt, analysis_title, R_2, start_phi, nbins=200,\n",
    "        show_gmnn = False, pol_sort_well_plate = [], pol_sort_ab_nuc = [], pol_sort_centered_data0 = [], pol_sort_centered_data1 = []):\n",
    "    '''\n",
    "    Visualize the log-FUCCI intensities and phase transitions.\n",
    "    If `show_gmnn` is true, generate an overlay of the GMNN antibody staining intensities.\n",
    "    '''\n",
    "    fig, ax1 = plt.subplots(figsize=(10,10))\n",
    "    mycmap = copy.copy(plt.cm.get_cmap(\"gray_r\"))\n",
    "    mycmap.set_under(color='w',alpha=None)\n",
    "    ax1.hist2d(centered_data[:,0],centered_data[:,1],bins=nbins,alpha=1,cmap=mycmap)\n",
    "    hist, xbins, ybins = np.histogram2d(cart_data_ur[0], cart_data_ur[1], bins=nbins, density=True)\n",
    "    extent = [xbins.min(),xbins.max(),ybins.min(),ybins.max()]\n",
    "    im = ax1.imshow(\n",
    "            np.ma.masked_where(hist == 0, hist).T,\n",
    "            interpolation='nearest',\n",
    "            origin='lower',\n",
    "            extent=extent,\n",
    "            cmap='plasma')\n",
    "    if show_gmnn: # GMNN was tagged in the FUCCI cells and stained with antibodies; visualize the agreement\n",
    "        gmnn = \"H05_55405991\"\n",
    "        gmnn_well_inds = pol_sort_well_plate==gmnn\n",
    "        gmnn_ab_nuc = pol_sort_ab_nuc[gmnn_well_inds]\n",
    "        im = ax1.scatter(pol_sort_centered_data0[gmnn_well_inds],pol_sort_centered_data1[gmnn_well_inds], c=gmnn_ab_nuc)\n",
    "        fig.colorbar(im, ax=ax1)\n",
    "    else:\n",
    "        plt.scatter(start_pt[0],start_pt[1],c='c',linewidths=4)\n",
    "        plt.scatter(g1_end_pt[0],g1_end_pt[1],c='c',linewidths=4)\n",
    "        plt.scatter(g1s_end_pt[0],g1s_end_pt[1],c='c',linewidths=4)\n",
    "        plt.scatter(0,0,c='m',linewidths=4)\n",
    "        plt.annotate(\"  0 hrs (start)\", (start_pt[0],start_pt[1]))\n",
    "        plt.annotate(f\"  {fucci.G1_LEN} hrs (end of G1)\", (g1_end_pt[0],g1_end_pt[1]))\n",
    "        plt.annotate(f\"  {fucci.G1_LEN + fucci.G1_S_TRANS} hrs (end of S)\", (g1s_end_pt[0],g1s_end_pt[1]))\n",
    "        for yeah in list(drange(decimal.Decimal(0.1), 0.9, '0.1')):\n",
    "            plot_annotate_time(R_2, start_phi, yeah)\n",
    "    plt.xlabel(r'$\\propto log_{10}(GMNN_{fucci})$',size=20)\n",
    "    plt.ylabel(r'$\\propto log_{10}(CDT1_{fucci})$',size=20)\n",
    "    plt.tight_layout()\n",
    "    if show_gmnn:\n",
    "        plt.savefig('figures/GMNN_FUCCI_plot.pdf', transparent=True)\n",
    "    else:\n",
    "        plt.savefig(f'figures/masked_polar_hist_{analysis_title}.pdf', transparent=True)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "## STRETCH TIME\n",
    "def frange(start, stop, step):\n",
    "    i = start\n",
    "    while i < stop:\n",
    "        yield i\n",
    "        i = round(i + step, 14)\n",
    "\n",
    "def histedges_equalN(x, nbin):\n",
    "    npt = len(x)\n",
    "    return np.interp(np.linspace(0, npt, nbin + 1), np.arange(npt), np.sort(x))\n",
    "\n",
    "def histedges_equalA(x, nbin):\n",
    "    pow = 0.5\n",
    "    dx = np.diff(np.sort(x))\n",
    "    tmp = np.cumsum(dx ** pow)\n",
    "    tmp = np.pad(tmp, (1, 0), 'constant')\n",
    "    return np.interp(np.linspace(0, tmp.max(), nbin + 1), tmp, np.sort(x))\n",
    "\n",
    "def stretch_time(time_data,nbins=1000):\n",
    "    '''This function is supposed to create uniform density space'''\n",
    "    n, bins, patches = plt.hist(time_data, histedges_equalN(time_data, nbins), density=True)\n",
    "    tmp_time_data = deepcopy(time_data)\n",
    "    trans_time = np.zeros([len(time_data)])\n",
    "    \n",
    "    # Get bin indexes\n",
    "    for i,c_bin in enumerate(bins[1:]):\n",
    "        c_inds = np.argwhere(tmp_time_data<c_bin)\n",
    "        trans_time[c_inds] = i/nbins\n",
    "        tmp_time_data[c_inds] = np.inf\n",
    "    return trans_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting the time at zero\n",
    "\n",
    "We can create a circle, but where do we start the cell cycle? One option that we used is to start it at the point where there is the least density of points. Because our dataset did not cover mitosis, this is likely the point of mitosis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fucci_polar_coords(x, y, analysis_title):\n",
    "    '''\n",
    "    Calculate the polar coordinate position of each cell based on the FUCCI intensities (x, y).\n",
    "    '''\n",
    "    fucci_data = np.column_stack([x, y])\n",
    "    center_est_xy = np.mean(x), np.mean(y)\n",
    "    center_est2_xy = scipy.optimize.least_squares(f_2, center_est_xy, args=(x, y))\n",
    "    xc_2, yc_2 = center_est2_xy.x\n",
    "    Ri_2       = calc_R(*center_est2_xy.x,x,y)\n",
    "    R_2        = Ri_2.mean()\n",
    "    residu_2   = sum((Ri_2 - R_2)**2)\n",
    "\n",
    "    # Center data\n",
    "    centered_data = fucci_data - center_est2_xy.x\n",
    "\n",
    "    pol_data = cart2pol(centered_data[:,0],centered_data[:,1])\n",
    "    pol_sort_inds = np.argsort(pol_data[1])\n",
    "    pol_sort_rho = pol_data[0][pol_sort_inds]\n",
    "    pol_sort_phi = pol_data[1][pol_sort_inds]\n",
    "    centered_data_sort0 = centered_data[pol_sort_inds,0]\n",
    "    centered_data_sort1 = centered_data[pol_sort_inds,1]\n",
    "\n",
    "    # Rezero to minimum --resoning, cells disappear during mitosis, so we should have the fewest detected cells there\n",
    "    bins = plt.hist(pol_sort_phi,NBINS_POLAR_COORD)\n",
    "    start_phi = bins[1][np.argmin(bins[0])]\n",
    "\n",
    "    # Move those points to the other side\n",
    "    more_than_start = np.greater(pol_sort_phi,start_phi)\n",
    "    less_than_start = np.less_equal(pol_sort_phi,start_phi)\n",
    "    pol_sort_rho_reorder = np.concatenate((pol_sort_rho[more_than_start],pol_sort_rho[less_than_start]))\n",
    "    pol_sort_inds_reorder = np.concatenate((pol_sort_inds[more_than_start],pol_sort_inds[less_than_start]))\n",
    "    pol_sort_phi_reorder = np.concatenate((pol_sort_phi[more_than_start],pol_sort_phi[less_than_start]+np.pi*2))\n",
    "    pol_sort_centered_data0 = np.concatenate((centered_data_sort0[more_than_start],centered_data_sort0[less_than_start]))\n",
    "    pol_sort_centered_data1 = np.concatenate((centered_data_sort1[more_than_start],centered_data_sort1[less_than_start]))\n",
    "    pol_sort_shift = pol_sort_phi_reorder+np.abs(np.min(pol_sort_phi_reorder))\n",
    "\n",
    "    # Shift and re-scale \"time\"\n",
    "    # reverse \"time\" since the cycle goes counter-clockwise wrt the fucci plot\n",
    "    pol_sort_norm = pol_sort_shift/np.max(pol_sort_shift)\n",
    "    pol_sort_norm_rev = 1 - pol_sort_norm \n",
    "    pol_sort_norm_rev = stretch_time(pol_sort_norm_rev)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"figures/FucciAllPseudotimeHist_{analysis_title}.png\")\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    # visualize that result\n",
    "    start_pt = pol2cart(R_2,start_phi)\n",
    "    g1_end_pt = pol2cart(R_2,start_phi + (1 - fucci.G1_PROP) * 2 * np.pi)\n",
    "    g1s_end_pt = pol2cart(R_2,start_phi + (1 - fucci.G1_S_PROP) * 2 * np.pi)\n",
    "    cart_data_ur = pol2cart(np.repeat(R_2,len(centered_data)), pol_data[1])\n",
    "    fucci_hist2d(centered_data, cart_data_ur, start_pt, g1_end_pt, g1s_end_pt, analysis_title, R_2, start_phi)\n",
    "\n",
    "    return (pol_sort_norm_rev, centered_data, pol_sort_centered_data0, pol_sort_centered_data1, pol_sort_phi, pol_sort_inds, pol_sort_inds_reorder, pol_sort_phi_reorder,\n",
    "        more_than_start, less_than_start, start_pt, g1_end_pt, g1s_end_pt, cart_data_ur, R_2, start_phi)\n",
    "\n",
    "# Generate model\n",
    "polar_coord_results = fucci_polar_coords(fucci_data[:,0], fucci_data[:,1], \"Protein\")\n",
    "pol_sort_norm_rev, centered_data, pol_sort_centered_data0, pol_sort_centered_data1, pol_sort_phi, pol_sort_inds, pol_sort_inds_reorder, pol_sort_phi_reorder, more_than_start, less_than_start, start_pt, g1_end_pt, g1s_end_pt, cart_data_ur, R_2, start_phi = polar_coord_results\n",
    "\n",
    "# Sort results by pseudotime\n",
    "sort_results = pol_sort(pol_sort_inds, more_than_start, less_than_start, well_plate, well_plate_imgnb, well_plate_imgnb_objnb, np.asarray(ab_nuc), np.asarray(ab_cyto), np.asarray(ab_cell), np.asarray(mt_cell), np.asarray(area_cell), np.asarray(area_nuc), log_red_fucci_zeroc_rescale, log_green_fucci_zeroc_rescale, mockbulk_phases)\n",
    "pol_sort_well_plate, pol_sort_well_plate_imgnb, pol_sort_well_plate_imgnb_objnb, pol_sort_ab_nuc, pol_sort_ab_cyto, pol_sort_ab_cell, pol_sort_mt_cell, pol_sort_area_cell, pol_sort_area_nuc, pol_sort_fred, pol_sort_fgreen, pol_sort_mockbulk_phases = sort_results\n",
    "    \n",
    "# Generate some plots\n",
    "fucci_hist2d(centered_data, cart_data_ur, start_pt, g1_end_pt, g1s_end_pt, \"Protein\", R_2, start_phi, 200, True, pol_sort_well_plate, pol_sort_ab_nuc, pol_sort_centered_data0, pol_sort_centered_data1)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We now have calculated a pseudotime for each cell!\n",
    "\n",
    "Multiply that by 25.3 hrs for each division, and you have the actual time within the cell division cycle for each cell, along with some protein expression information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the error in the cell cycle time determination?\n",
    "\n",
    "Let's plot the marker expression over cell cycle time to figure out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mvavg(yvals, mv_window):\n",
    "    '''Calculate the moving average'''\n",
    "    return np.convolve(yvals, np.ones((mv_window,))/mv_window, mode='valid')\n",
    "def mvpercentiles(yvals_binned):\n",
    "    '''Calculate moving percentiles given moving-window binned values'''\n",
    "    return np.percentile(yvals_binned, [10, 25, 50, 75, 90], axis=1)\n",
    "\n",
    "def plot_fucci_intensities_on_pseudotime(pol_sort_norm_rev, pol_sort_centered_data1, pol_sort_centered_data0):\n",
    "    '''Visualize FUCCI intensities over pseudotime'''\n",
    "    plt.figure(figsize=(5,5))\n",
    "    WINDOW_FUCCI_PSEUDOTIMEs = np.asarray([np.arange(start, start + WINDOW_FUCCI_PSEUDOTIME) for start in np.arange(len(pol_sort_norm_rev) - WINDOW_FUCCI_PSEUDOTIME + 1)])\n",
    "    mvperc_red = mvpercentiles(pol_sort_centered_data1[WINDOW_FUCCI_PSEUDOTIMEs])\n",
    "    mvperc_green = mvpercentiles(pol_sort_centered_data0[WINDOW_FUCCI_PSEUDOTIMEs])\n",
    "    mvavg_xvals = mvavg(pol_sort_norm_rev, WINDOW_FUCCI_PSEUDOTIME)\n",
    "    plt.fill_between(mvavg_xvals * fucci.TOT_LEN, mvperc_green[1], mvperc_green[-2], color=\"lightgreen\", label=\"25th & 75th Percentiles\")\n",
    "    plt.fill_between(mvavg_xvals * fucci.TOT_LEN, mvperc_red[1], mvperc_red[-2], color=\"lightcoral\", label=\"25th & 75th Percentiles\")\n",
    "    \n",
    "    mvavg_red = mvavg(pol_sort_centered_data1, WINDOW_FUCCI_PSEUDOTIME)\n",
    "    mvavg_green = mvavg(pol_sort_centered_data0, WINDOW_FUCCI_PSEUDOTIME)\n",
    "    plt.plot(mvavg_xvals * fucci.TOT_LEN, mvavg_red, color=\"r\", label=\"Mean Intensity\")\n",
    "    plt.plot(mvavg_xvals * fucci.TOT_LEN, mvavg_green, color=\"g\", label=\"Mean Intensity\")\n",
    "    plt.xlabel('Cell Cycle Time, hrs')\n",
    "    plt.ylabel('Log10 Tagged CDT1 & GMNN Intensity')\n",
    "    plt.xticks(size=14)\n",
    "    plt.yticks(size=14)\n",
    "    # plt.ylim(0, 1)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"figures/FUCCIOverPseudotime.pdf\")\n",
    "    plt.savefig(\"figures/FUCCIOverPseudotime.png\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "plot_fucci_intensities_on_pseudotime(pol_sort_norm_rev, pol_sort_centered_data1, pol_sort_centered_data0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion:\n",
    "\n",
    "The 25th and 75th percentiles of the marker intensity shown by the light colored ranges are fairly tight over the whole cell cycle, indicating the error is acceptable for cell cycle determination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking a look at a cycling protein\n",
    "\n",
    "One of the most interesting cycling proteins we found was UGDH, which is not regulated at the transcriptional level and is a newly discovered cycling protein.\n",
    "\n",
    "We also used live-cell imaging to reveal that this protein is translocating between the cytosol to the nucleus over the cell cycle.\n",
    "\n",
    "![ugdh](ugdh.png \"UGDH\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a plot to display the expression of UGDH over the cell cycle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3:\n",
    "Use the polar coordinate shifted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FucciCellCycle:\n",
    "    '''\n",
    "    Object representing the length of the FUCCI cell cycle phase transitions, which\n",
    "    were manually determined by Diana M.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        # Length of the cell cycle observed for the FUCCI cell line\n",
    "        self.G1_LEN = 10.833 #hours (plus 10.833, so 13.458hrs for the S/G2 cutoff)\n",
    "        self.G1_S_TRANS = 2.625 #hours (plus 10.833 and 2.625 so 25.433 hrs for the G2/M cutoff)\n",
    "        self.S_G2_LEN = 11.975 #hours (this should be from the G2/M cutoff above to the end)\n",
    "        self.M_LEN = 0.5 # We excluded M-phase from this analysis\n",
    "\n",
    "        self.TOT_LEN = self.G1_LEN+self.G1_S_TRANS+self.S_G2_LEN\n",
    "\n",
    "        self.G1_PROP = self.G1_LEN / self.TOT_LEN\n",
    "        self.G1_S_PROP = self.G1_S_TRANS / self.TOT_LEN + self.G1_PROP\n",
    "        self.S_G2_PROP = self.S_G2_LEN / self.TOT_LEN + self.G1_S_PROP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0) # Get the same results each time\n",
    "WINDOW = 10 # Number of points for moving average window for protein analysis\n",
    "WINDOW_FUCCI_MARKERS = 100 # Used for getting median FUCCI marker intensity for LASSO analysis\n",
    "PERMUTATIONS = 10000 # Number of permutations used for randomization analysis\n",
    "MIN_MEAN_PERCVAR_DIFF_FROM_RANDOM = 0.08 # Cutoff used for percent additional variance explained by the cell cycle than random\n",
    "BINS_FOR_UMAP_AND_LASSO = 400 # Number of bins for creating UMAPs/LASSO model. Chosen for the best stability.\n",
    "chosen_cutoff = MIN_MEAN_PERCVAR_DIFF_FROM_RANDOM\n",
    "\n",
    "def permutation_analysis_protein(idx, curr_pol, curr_ab_cell_norm, curr_ab_nuc_norm, curr_ab_cyto_norm, curr_mt_cell_norm,\n",
    "        perc_var_cell_val, perc_var_nuc_val, perc_var_cyto_val,\n",
    "        wp_iscell, wp_isnuc, wp_iscyto,\n",
    "        mvavg_cell, mvavg_nuc, mvavg_cyto):\n",
    "    '''Randomization analysis of cell cycle dependence: permute cell order and calculate percent variance due to the cell cycle'''\n",
    "    perms = np.asarray([np.random.permutation(len(curr_pol)) for nnn in np.arange(PERMUTATIONS)])\n",
    "    curr_comp_norm = np.asarray(curr_ab_cell_norm if wp_iscell[idx] else curr_ab_nuc_norm if wp_isnuc[idx] else curr_ab_cyto_norm)\n",
    "    curr_comp_percvar = np.asarray(perc_var_cell_val if wp_iscell[idx] else perc_var_nuc_val if wp_isnuc[idx] else perc_var_cyto_val)\n",
    "    curr_comp_mvavg = np.asarray(mvavg_cell if wp_iscell[idx] else mvavg_nuc if wp_isnuc[idx] else mvavg_cyto)\n",
    "    curr_comp_perm = np.asarray([curr_comp_norm[perm] for perm in perms])\n",
    "    curr_mt_perm = np.asarray([curr_mt_cell_norm[perm] for perm in perms])\n",
    "    curr_mvavg_rng_comp = np.apply_along_axis(mvavg, 1, curr_comp_perm, WINDOW)\n",
    "    curr_mvavg_rng_mt = np.apply_along_axis(mvavg, 1, curr_mt_perm, WINDOW)\n",
    "    curr_percvar_rng_comp = np.var(curr_mvavg_rng_comp, axis=1) / np.var(curr_comp_perm, axis=1)\n",
    "    curr_percvar_rng_mt = np.var(curr_mvavg_rng_mt, axis=1) / np.var(curr_mt_perm, axis=1)\n",
    "    return (curr_comp_norm, curr_comp_percvar, curr_comp_mvavg, curr_comp_perm, curr_mt_perm, \n",
    "        curr_mvavg_rng_comp, curr_mvavg_rng_mt, curr_percvar_rng_comp, curr_percvar_rng_mt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mvmed(yvals_binned):\n",
    "    '''Calculate the moving median given moving-window binned values'''\n",
    "    return np.median(yvals_binned, axis=1)\n",
    "def mvmed_perc_var(yvals, windows):\n",
    "    '''Calculate moving median and the percent variance that can be attributed to the cell cycle'''\n",
    "    yval_avg = mvmed(yvals[windows])\n",
    "    return np.var(yval_avg) / np.var(yvals), yval_avg\n",
    "def mvavg_perc_var(yvals,mv_window):\n",
    "    '''Calculate moving average and the percent variance that can be attributed to cell cycle'''\n",
    "    yval_avg = np.convolve(yvals,np.ones((mv_window,))/mv_window, mode='valid')\n",
    "    return np.var(yval_avg)/np.var(yvals), yval_avg\n",
    "    \n",
    "def remove_outliers_idx(values):\n",
    "    '''Returns indices of outliers to keep'''\n",
    "    max_cutoff = np.mean(values) + 2 * np.std(values)\n",
    "    min_cutoff = np.mean(values) - 2 * np.std(values)\n",
    "    return (values < max_cutoff) & (values > min_cutoff)\n",
    "\n",
    "def remove_outliers(values, return_values):\n",
    "    '''Remove outliers on \"values\" and return \"return_values\" based on that filter'''\n",
    "    return return_values[remove_outliers_idx(values)]\n",
    "\n",
    "ugdh_well = \"D02_55215982\"\n",
    "i=np.arange(len(u_well_plates))[u_well_plates == ugdh_well]\n",
    "curr_well_inds = pol_sort_well_plate==ugdh_well\n",
    "curr_pol = pol_sort_norm_rev[curr_well_inds]\n",
    "# EXERCISE 3A: Retrieve the nuclear antibody intensities in the same way,\n",
    "# and use the remove_outliers method to get a list of protein intensities for UGDH\n",
    "# Please use the nuclear intensities, since that's the annotated location, although we recently showed it is also located in the cytosol.\n",
    "\n",
    "# EXERCISE 3B:\n",
    "# Plot those over the pseudotime in variable `cur_pol`\n",
    "\n",
    "# Normalize mean intensities, normalized for display\n",
    "curr_ab_cell_norm = curr_ab_cell / np.max(curr_ab_cell) \n",
    "curr_ab_nuc_norm = curr_ab_nuc / np.max(curr_ab_nuc)\n",
    "curr_ab_cyto_norm = curr_ab_cyto / np.max(curr_ab_cyto) \n",
    "curr_mt_cell_norm  = curr_mt_cell / np.max(curr_mt_cell)\n",
    "\n",
    "# Original method from Devin's work\n",
    "perc_var_cell_val, mvavg_cell = mvavg_perc_var(curr_ab_cell_norm, WINDOW)\n",
    "perc_var_nuc_val, mvavg_nuc = mvavg_perc_var(curr_ab_nuc_norm, WINDOW)\n",
    "perc_var_cyto_val, mvavg_cyto = mvavg_perc_var(curr_ab_cyto_norm, WINDOW)\n",
    "perc_var_mt_val, mvavg_mt = mvavg_perc_var(curr_mt_cell_norm, WINDOW)\n",
    "mvavg_xvals = mvavg(curr_pol, WINDOW)\n",
    "\n",
    "# EXERCISE 3C: Overlay these moving average values onto the plot from before\n",
    "\n",
    "# Permutation analysis\n",
    "permutation_result = permutation_analysis_protein(i, \n",
    "                            curr_pol, curr_ab_cell_norm, curr_ab_nuc_norm, curr_ab_cyto_norm, curr_mt_cell_norm,\n",
    "                            perc_var_cell_val, perc_var_nuc_val, perc_var_cyto_val, \n",
    "                            wp_iscell, wp_isnuc, wp_iscyto, \n",
    "                            mvavg_cell, mvavg_nuc, mvavg_cyto)\n",
    "curr_comp_norm, curr_comp_percvar, curr_comp_mvavg, curr_comp_perm, curr_mt_perm, curr_mvavg_rng_comp, curr_mvavg_rng_mt, curr_percvar_rng_comp, curr_percvar_rng_mt = permutation_result\n",
    "mvavg_comp = mvavg_cell if wp_iscell[i] else mvavg_nuc if wp_isnuc[i] else mvavg_cyto\n",
    "curr_ab_norm = curr_ab_cell_norm if wp_iscell[i] else curr_ab_nuc_norm if wp_isnuc[i] else curr_ab_cyto_norm\n",
    "windows = np.asarray([np.arange(start, start + WINDOW) for start in np.arange(len(curr_pol) - WINDOW + 1)])\n",
    "mvavg_comp = mvavg_nuc\n",
    "curr_ab_norm = curr_ab_nuc_norm\n",
    "\n",
    "windows = np.asarray([np.arange(start, start + WINDOW) for start in np.arange(len(curr_pol) - WINDOW + 1)])\n",
    "mvperc_comp = mvpercentiles(curr_ab_norm[windows])\n",
    "\n",
    "# Exercise 3D: Overlay these moving percentiles onto the plot from before"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
